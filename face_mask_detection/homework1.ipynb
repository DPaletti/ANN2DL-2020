{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN2DL Homework 1: Face Mask Detection\n",
    "## Splitting training and validation pictures in Keras-compatible directory structures\n",
    "Validation set size is chosen so as to be equal to the test set size given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell output set upf for Jupyter\n",
    "from pathlib import Path\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "\n",
    "test_pictures_n = 450 # validation set size is set equal to test set size\n",
    "target_file_name = \"train_gt.json\"\n",
    "dataset_name = \"MaskDataset\"\n",
    "\n",
    "# Setting up directory structure\n",
    "Path().joinpath(dataset_name, \"validation\").mkdir(parents=True, exist_ok=True)\n",
    "Path().joinpath(dataset_name, \"training\", \"NO_PERSON\").mkdir(parents=True, exist_ok=True)\n",
    "Path().joinpath(dataset_name, \"training\", \"ALL_THE_PEOPLE\").mkdir(parents=True, exist_ok=True)\n",
    "Path().joinpath(dataset_name, \"training\", \"SOMEONE\").mkdir(parents=True, exist_ok=True)\n",
    "Path().joinpath(dataset_name, \"validation\", \"NO_PERSON\").mkdir(parents=True, exist_ok=True)\n",
    "Path().joinpath(dataset_name, \"validation\", \"ALL_THE_PEOPLE\").mkdir(parents=True, exist_ok=True)\n",
    "Path().joinpath(dataset_name, \"validation\", \"SOMEONE\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Files are moved from the training directory to the corresponding folders\n",
    "# both for training and for validation\n",
    "with open(str(Path().joinpath(dataset_name, target_file_name))) as f:\n",
    "    data = json.load(f)\n",
    "    pictures = list(data.keys())\n",
    "    random.shuffle(pictures)\n",
    "    validation_pictures = pictures[0:test_pictures_n]\n",
    "    for path in Path().joinpath(dataset_name, \"training\").glob(\"*.jpg\"):\n",
    "        if path.name in validation_pictures:\n",
    "            file_destination = str(Path().joinpath(dataset_name, \"validation\", path.name))\n",
    "            path.rename(file_destination)\n",
    "            path = Path(file_destination)\n",
    "        if data[path.name] == 0:\n",
    "            path.rename(str(Path(path.parent).joinpath(\"NO_PERSON\", path.name)))\n",
    "        elif data[path.name] == 1:\n",
    "            path.rename(str(Path(path.parent).joinpath(\"ALL_THE_PEOPLE\", path.name)))\n",
    "        elif data[path.name] == 2:\n",
    "            path.rename(str(Path(path.parent).joinpath(\"SOMEONE\", path.name)))\n",
    "        else:\n",
    "            raise ValueError(\"Unrecognized label in \" + target_file_name + \" allowed values are 0, 1, 2 found: \" + str(data[path.name]))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset handling and augmentation\n",
    "ImageDataGenerator handles data augmentation and the data flows from the directory which is now compliant with Keras requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images must be resized at least to: 345 * 256\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Getting the size of all images\n",
    "image_size_set = set()\n",
    "for path in Path().joinpath(dataset_name).glob(\"**/*.jpg\"):\n",
    "    image_size_set.add(Image.open(str(path)).size)\n",
    "    \n",
    "# Looking for smaller width and height in the dataset\n",
    "w_min = np.inf\n",
    "h_min = np.inf\n",
    "for t in image_size_set:\n",
    "    if t[0] < w_min:\n",
    "        w_min = t[0]\n",
    "    if t[1] < h_min:\n",
    "        h_min = t[1]\n",
    "print(\"Images must be resized at least to: \" + str(w_min) + \" * \" + str(h_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Batches\n",
    "bs = 32\n",
    "\n",
    "# Data augmentation switch\n",
    "apply_data_augmentation = False\n",
    "if apply_data_augmentation:\n",
    "    train_data_gen = ImageDataGenerator(zoom_range=0.2,\n",
    "                                        rescale=1./255)\n",
    "else:\n",
    "       train_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "valid_data_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomAugment(object):\n",
    "    def __call__(self, image):        \n",
    "        img = self._random_apply(self._color_drop, image, p=0.8)\n",
    "        return img\n",
    "    def __name__(self):\n",
    "        return \"CustomAugment\"\n",
    "\n",
    "    def _color_drop(self, x):\n",
    "        image = tf.image.rgb_to_grayscale(x)\n",
    "        image = tf.tile(x, [1, 1, 1, 3])\n",
    "        return x\n",
    "    \n",
    "    def _random_apply(self, func, x, p):\n",
    "        return tf.cond(\n",
    "          tf.less(tf.random.uniform([], minval=0, maxval=1, dtype=tf.float32),\n",
    "                  tf.cast(p, tf.float32)),\n",
    "          lambda: func(x),\n",
    "          lambda: x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5164 images belonging to 3 classes.\n",
      "Found 450 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = Path().joinpath(dataset_name)\n",
    "\n",
    "\n",
    "# Target Image Shape\n",
    "# Largest image size would be 358 x 256\n",
    "img_h = 256\n",
    "img_w = 256\n",
    "\n",
    "num_classes = 3\n",
    "classes = [\"NO_PERSON\",\n",
    "          \"ALL_THE_PEOPLE\",\n",
    "          \"SOMEONE\"]\n",
    "\n",
    "training_dir = dataset_dir.joinpath(\"training\")\n",
    "train_gen = train_data_gen.flow_from_directory(str(training_dir),\n",
    "                                              batch_size=bs,\n",
    "                                              classes=classes,\n",
    "                                              class_mode=\"categorical\",\n",
    "                                              shuffle=True,\n",
    "                                              target_size=(img_h, img_w),\n",
    "                                              seed=SEED)\n",
    "\n",
    "validation_dir = dataset_dir.joinpath(\"validation\")\n",
    "valid_gen = valid_data_gen.flow_from_directory(str(validation_dir),\n",
    "                                              batch_size=bs,\n",
    "                                              classes=classes,\n",
    "                                              class_mode=\"categorical\",\n",
    "                                              shuffle=True,\n",
    "                                              target_size=(img_h, img_w),\n",
    "                                              seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_generator(lambda: train_gen,\n",
    "                                              output_types=(tf.float32, tf.float32),\n",
    "                                              output_shapes=([None, img_h, img_w, 3], [None, num_classes]))\n",
    "train_dataset = train_dataset.repeat()\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen, \n",
    "                                              output_types=(tf.float32, tf.float32),\n",
    "                                              output_shapes=([None, img_h, img_w, 3], [None, num_classes]))\n",
    "valid_dataset = valid_dataset.repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model specification - 1\n",
    "The approach in https://arxiv.org/pdf/2009.08369.pdf is used as a starting point so:\n",
    "- Inception V3 Model stripped of the last layer\n",
    "- 5 layers added:\n",
    "    - average pooling layer 5x5\n",
    "    - flattening layer\n",
    "    - dense layer with 128 Neurons with ReLU activation\n",
    "    - dropout layer with 0.5 dropout probability\n",
    "    - decision layer with softmax activations\n",
    "- we generally leverage transfer learning but being that the last pooling layer is brand new we are tuning its parameters and the ones of the multi-layer perceptron\n",
    "\n",
    "- Random gray scale, instead of uniform gray scaling in the paper, is applied together with flips and zooms which in the paper are not present\n",
    "\n",
    "Batch Size = 8 -> 32  \n",
    "\n",
    "\n",
    "TODO: retrain it with pre-processed dataset\n",
    "TODO: evaluate unfreezing some inception layers  \n",
    "TODO: evaluate using full inception and not adding the new layer  \n",
    "TODO: evaluate adding more convolutional layers after inception  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Load InceptionV3 model and strip last layer\n",
    "\n",
    "inception = tf.keras.applications.InceptionV3(weights=\"imagenet\", include_top=False, input_shape=(img_h, img_w, 3))\n",
    "inception = tf.keras.models.Model(inputs = inception.input, outputs = inception.layers[-2].output) # removing last inception layer\n",
    "train_dataset = train_dataset.map(lambda x, y: (tf.keras.applications.inception_v3.preprocess_input(x), y))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "inception.trainable = False # freezing all model\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(inception)\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(5, 5)))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(units=num_classes, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "lr = 1e-3\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "metrics = ['accuracy']\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Specification - 2\n",
    "Based on: https://gist.github.com/didacroyo/839bd1dbb67463df8ba8fb14eb3fde0c\n",
    "Transfer Learning with Inception V3.\n",
    "1. Train all top layers and freeze Inception V3 for 20 epochs without early stopping\n",
    "2. Keep layers between 0-249 frozen and unfreeze the rest, lower the learning rate and re-train for 100 epochs with early stopping  \n",
    "Batch Size = 8 -> 4\n",
    "epochs = 20 + 100 -> 100 (skipped first step)\n",
    "Early stopping on second training  \n",
    "Data Augmentation Standard + Custom Grey scaling"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "inception = tf.keras.applications.InceptionV3(weights=\"imagenet\", include_top=False, input_shape=(img_h, img_w, 3))\n",
    "train_dataset = train_dataset.map(lambda x, y: (tf.keras.applications.inception_v3.preprocess_input(x), y))\n",
    "inception.trainable = False\n",
    "model = tf.keras.Sequential()\n",
    "model.add(inception)\n",
    "model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(units=512, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.4))\n",
    "model.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(units=num_classes, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# First train round with higher learning rate\n",
    "# 20 epochs\n",
    "\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "lr = 1e-3\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
    "metrics = ['accuracy']\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Run this after first train or after loading model_2_pre_trained_top.h5\n",
    "# Second unfreeze some layers and lower learning rate\n",
    "# Early Stop is activated to avoid overfitting\n",
    "# 100 epochs\n",
    "for layer in model.layers[:249]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "    layer.trainable = True # unfreezing last two inception blocks\n",
    "    \n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "metrics = ['accuracy']\n",
    "lr = 0.3\n",
    "optimizer = tf.keras.optimizers.Adam(lr=lr)\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Specification - 3\n",
    "Vgg16 with pre-processing on input  \n",
    "batch size = 16  \n",
    "Early Stopping = True  \n",
    "Data Augmentation Custom (Data Augmentation Switch to False)\n",
    "TODO: try with VGG19 (is slow)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vgg16 = tf.keras.applications.VGG16(weights=\"imagenet\", include_top=False, input_shape=(img_h, img_w, 3))\n",
    "\n",
    "train_dataset = train_dataset.map(lambda x, y: (tf.keras.applications.vgg19.preprocess_input(x), y))\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(vgg16)\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(units=num_classes, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for layer in vgg16.layers[-4:-1]:\n",
    "    layer.trainable = True\n",
    "for layer in vgg16.layers[:-5]:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam() # default learning rate 0.001\n",
    "metrics = ['accuracy']\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Specification - 4 (ShuffleNet)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.activations import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "\n",
    "def _stage(tensor, nb_groups, in_channels, out_channels, repeat):\n",
    "    x = _shufflenet_unit(tensor, nb_groups, in_channels, out_channels, 2)\n",
    "\n",
    "    for _ in range(repeat):\n",
    "        x = _shufflenet_unit(x, nb_groups, out_channels, out_channels, 1)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def _pw_group(tensor, nb_groups, in_channels, out_channels):\n",
    "    \"\"\"Pointwise grouped convolution.\"\"\"\n",
    "    nb_chan_per_grp = in_channels // nb_groups\n",
    "\n",
    "    pw_convs = []\n",
    "    for grp in range(nb_groups):\n",
    "        x = Lambda(lambda x: x[:, :, :, nb_chan_per_grp * grp: nb_chan_per_grp * (grp + 1)])(tensor)\n",
    "        grp_out_chan = int(out_channels / nb_groups + 0.5)\n",
    "\n",
    "        pw_convs.append(\n",
    "            Conv2D(grp_out_chan,\n",
    "                   kernel_size=(1, 1),\n",
    "                   padding='same',\n",
    "                   use_bias=False,\n",
    "                   strides=1)(x)\n",
    "        )\n",
    "\n",
    "    return Concatenate(axis=-1)(pw_convs)\n",
    "\n",
    "\n",
    "def _shuffle(x, nb_groups):\n",
    "    def shuffle_layer(x):\n",
    "        _, w, h, n = K.int_shape(x)\n",
    "        nb_chan_per_grp = n // nb_groups\n",
    "\n",
    "        x = K.reshape(x, (-1, w, h, nb_chan_per_grp, nb_groups))\n",
    "        x = K.permute_dimensions(x, (0, 1, 2, 4, 3)) # Transpose only grps and chs\n",
    "        x = K.reshape(x, (-1, w, h, n))\n",
    "\n",
    "        return x\n",
    "\n",
    "    return Lambda(shuffle_layer)(x)\n",
    "\n",
    "\n",
    "def _shufflenet_unit(tensor, nb_groups, in_channels, out_channels, strides, shuffle=True, bottleneck=4):\n",
    "    bottleneck_channels = out_channels // bottleneck\n",
    "\n",
    "    x = _pw_group(tensor, nb_groups, in_channels, bottleneck_channels)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    if shuffle:\n",
    "        x = _shuffle(x, nb_groups)\n",
    "\n",
    "    x = DepthwiseConv2D(kernel_size=(3, 3),\n",
    "                        padding='same',\n",
    "                        use_bias=False,\n",
    "                        strides=strides)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "\n",
    "    x = _pw_group(x, nb_groups, bottleneck_channels,\n",
    "                  out_channels if strides < 2 else out_channels - in_channels)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    if strides < 2:\n",
    "        x = Add()([tensor, x])\n",
    "    else:\n",
    "        avg = AveragePooling2D(pool_size=(3, 3),\n",
    "                               strides=2,\n",
    "                               padding='same')(tensor)\n",
    "\n",
    "        x = Concatenate(axis=-1)([avg, x])\n",
    "\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def _info(nb_groups):\n",
    "    return {\n",
    "        1: [24, 144, 288, 576],\n",
    "        2: [24, 200, 400, 800],\n",
    "        3: [24, 240, 480, 960],\n",
    "        4: [24, 272, 544, 1088],\n",
    "        8: [24, 384, 768, 1536]\n",
    "    }[nb_groups], [None, 3, 7, 3]\n",
    "\n",
    "\n",
    "def ShuffleNet(input_shape, nb_classes, include_top=True, weights=None, nb_groups=8):\n",
    "    x_in = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(24,\n",
    "               kernel_size=(3, 3),\n",
    "               strides=2,\n",
    "               use_bias=False,\n",
    "               padding='same')(x_in)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = MaxPooling2D(pool_size=(3, 3),\n",
    "                     strides=2,\n",
    "                     padding='same')(x)\n",
    "\n",
    "    channels_list, repeat_list = _info(nb_groups)\n",
    "    for i, (out_channels, repeat) in enumerate(zip(channels_list[1:], repeat_list[1:]), start=1):\n",
    "        x = _stage(x, nb_groups, channels_list[i-1], out_channels, repeat)\n",
    "\n",
    "    if include_top:\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(nb_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=x_in, outputs=x)\n",
    "\n",
    "    if weights is not None:\n",
    "        model.load_weights(weights, by_name=True)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "shuffle_net = ShuffleNet((img_h, img_w, 3), num_classes, include_top=False)\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Lambda(CustomAugment()))\n",
    "model.add(shuffle_net)\n",
    "model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(units=32, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(units=32, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(units=num_classes, activation=\"softmax\"))\n",
    "\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam() # default learning rate 0.001\n",
    "metrics = ['accuracy']\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Specification - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a linear stack of layers with the sequential model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.InputLayer(input_shape=(img_h, img_w, 3)))\n",
    "\n",
    "# convolutional layer\n",
    "model.add(tf.keras.layers.Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(25, (5, 5), activation='relu', strides=(1, 1), padding='same'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='same'))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(50, (5, 5), activation='relu', strides=(2, 2), padding='same'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='same'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(70, (3, 3), activation='relu', strides=(2, 2), padding='same'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='valid'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(units=100, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(units=100, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(units=num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "callbacks_dir = Path().joinpath(\"Callbacks\")\n",
    "callbacks_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "now = datetime.now().strftime(\"%b%d_%H-%M-%S\")\n",
    "\n",
    "model_name = \"CNN\"\n",
    "\n",
    "callback_dir = callbacks_dir.joinpath(model_name + '_' + str(now))\n",
    "callback_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "callbacks = []\n",
    "\n",
    "# Model checkpoint\n",
    "ckpt_dir = callback_dir.joinpath(\"ckpts\")\n",
    "ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=str(ckpt_dir.joinpath(\"cp.ckpt\")), \n",
    "                                                   save_weights_only=True)\n",
    "callbacks.append(ckpt_callback)\n",
    "\n",
    "# Visualize Learning on Tensorboard\n",
    "tb_dir = callback_dir.joinpath(\"tb_logs\")\n",
    "tb_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=str(tb_dir),\n",
    "                                             profile_batch=0,\n",
    "                                             histogram_freq=1) \n",
    "callbacks.append(tb_callback)\n",
    "\n",
    "# Early Stopping\n",
    "early_stop = True\n",
    "if early_stop:\n",
    "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    callbacks.append(es_callback)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!tensorboard --logdir ./Callbacks --port 6009"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "162/162 [==============================] - 94s 578ms/step - loss: 1.2070 - accuracy: 0.3734 - val_loss: 1.2307 - val_accuracy: 0.3622\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 83s 512ms/step - loss: 1.0698 - accuracy: 0.4355 - val_loss: 1.0524 - val_accuracy: 0.4333\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 82s 507ms/step - loss: 0.9846 - accuracy: 0.5015 - val_loss: 1.0402 - val_accuracy: 0.4533\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 83s 510ms/step - loss: 0.8683 - accuracy: 0.5864 - val_loss: 0.8657 - val_accuracy: 0.5978\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 83s 511ms/step - loss: 0.7248 - accuracy: 0.6784 - val_loss: 0.9530 - val_accuracy: 0.5356\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 83s 515ms/step - loss: 0.5863 - accuracy: 0.7409 - val_loss: 0.9209 - val_accuracy: 0.5622\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 83s 510ms/step - loss: 0.4485 - accuracy: 0.8034 - val_loss: 0.8387 - val_accuracy: 0.6489\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 82s 508ms/step - loss: 0.3108 - accuracy: 0.8792 - val_loss: 1.2153 - val_accuracy: 0.6000\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 83s 511ms/step - loss: 0.2259 - accuracy: 0.9171 - val_loss: 1.5890 - val_accuracy: 0.5622\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 83s 515ms/step - loss: 0.1446 - accuracy: 0.9516 - val_loss: 1.3086 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe228471b50>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_dataset,\n",
    "          epochs=10,\n",
    "          steps_per_epoch=len(train_gen),\n",
    "          validation_data=valid_dataset,\n",
    "          validation_steps=len(valid_gen), \n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(Path().joinpath(\"Results\", \"model\" + datetime.now().strftime('%b%d_%H-%M-%S')+ \".h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for path in Path().joinpath(dataset_name, \"test\").glob(\"*.jpg\"):\n",
    "    image = Image.open(str(path)).convert(\"RGB\")\n",
    "    image = image.resize((img_w, img_h), Image.ANTIALIAS)\n",
    "    image = np.array(image)\n",
    "    image = np.expand_dims(image, 0)\n",
    "    image = train_data_gen.normalize(image)\n",
    "    image = tf.keras.applications.inception_v3.preprocess_input(image) # !!!!! Change this line with correct pre-processing (erase it if not transfer learning)\n",
    "    results[path.name]= model.predict(image).argmax(axis=-1)[0] \n",
    "    \n",
    "    print(str(path.name) + \" \" + str(results[path.name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_fname = \"results_\" + datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n",
    "Path().joinpath(\"Results\").mkdir(parents=True, exist_ok=True)\n",
    "with open(Path().joinpath(\"Results\", csv_fname), \"w\") as f:\n",
    "    f.write(\"Id,Category\\n\")\n",
    "    for key, value in results.items():\n",
    "        f.write(key + ',' + str(value) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
